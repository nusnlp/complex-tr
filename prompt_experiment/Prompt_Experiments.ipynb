{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d71332a-0f3e-4b4e-883a-8f5b1c8b4938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    " \n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key='your API key',\n",
    ")\n",
    "def llm_chat(prompt):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "    )\n",
    "    return chat_completion\n",
    "\n",
    "def gpt4_chat(prompt):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-4-turbo-preview\",\n",
    "    )\n",
    "    return chat_completion\n",
    "def gpt4_6_chat(prompt):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-4-0613\",\n",
    "    )\n",
    "    return chat_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0781d92-79f7-45c0-8a52-db2c9e9e9993",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/54/vll8pfc15hq52jgzkklxt__00000gn/T/ipykernel_88312/156169343.py:8: FutureWarning: Metric is deprecated and will be removed in the next major version of datasets. Use the new library ü§ó Evaluate instead: https://huggingface.co/docs/evaluate\n",
      "  metric = Squad_SEM()\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "from sem_metric.sem_metric import Squad_SEM\n",
    "from datasets import load_dataset, load_metric\n",
    "import datasets\n",
    "\n",
    "\n",
    "metric = Squad_SEM()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcf4564e-6f0a-4bdf-b8b2-d146740159c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [json.loads(line) for line in open('../Documents/tr_v5/train_joint.json')]\n",
    "data = [json.loads(line) for line in open('test_gold_gcs.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2e79493-3463-4821-99b8-784de7791f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model('gpt-4-turbo')\n",
    "def process_context(text, length):\n",
    "    return encoding.decode(encoding.encode(text)[:length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "04f48409-cc73-476d-8e47-9852ed4c75b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given context: Henri Villat worked for Lyc√©e Malherbe from January 1902 to January 1906. \n",
      " Henri Villat worked for University of Caen Normandy from January 1906 to January 1911. \n",
      " Henri Villat worked for University of Strasbourg from January 1919 to January 1925. \n",
      " Henri Villat studied at Lyc√©e Malherbe from January 1886 to January 1899. \n",
      " Henri Villat worked for University of Montpellier from January 1911 to January 1919. \n",
      " Henri Villat studied at √âcole normale sup√©rieure  (Paris) from January 1899 to January 1902. Q: Where was Henri Villat educated in October 1901? A: √âcole normale sup√©rieure  (Paris).\n"
     ]
    }
   ],
   "source": [
    "example_prompt_template = 'Given context: {} Q: {} A: {}.'\n",
    "question_prompt_template = 'Please answer the questions given context: {}, Q: {}, please answer the names only, if there are multiple answers, please join them by \\'and\\' A:'\n",
    "i=1\n",
    "example_prompt = example_prompt_template.format(train_data[i]['fact_context'],train_data[i]['question'], ' and '.join(train_data[i]['text_answers']['text'] ))\n",
    "#example_prompt = example_prompt_template.format(process_context(train_data[i]['context'], 1024),train_data[i]['question'], ' and '.join(train_data[i]['text_answers']['text'] ))\n",
    "\n",
    "print(example_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33ee0c3-d55e-48b2-a144-461b477a4717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "ground_truth = []\n",
    "preds = []\n",
    "not_predicted = []\n",
    "for example in data:\n",
    "    question_prompt = question_prompt_template.format(example['fact_context'], example['question'])\n",
    "    prompt = example_prompt + question_prompt\n",
    "    try:\n",
    "        response = llm_chat(prompt)\n",
    "        prediction_text = response.choices[0].message.content\n",
    "        gt = {'id':example['id'], 'answers':{'text': example['text_answers']['text']}}\n",
    "        pred = {'id':example['id'], 'no_answer_probability':0,'prediction_text':prediction_text}\n",
    "        ground_truth.append(gt)\n",
    "        preds.append(pred)\n",
    "        time.sleep(1)\n",
    "    except:\n",
    "        not_predicted.append(example)\n",
    "        continue\n",
    "print(len(preds))\n",
    "scores=[]\n",
    "result = metric._compute( references=ground_truth, predictions=preds)\n",
    "scores += ['{:.2f}'.format(result['Set_Acc']),\"{:.2f}\".format(result['Answer_F1']),\"{:.2f}\".format(result['EM']) ,\"{:.2f}\".format(result['Token_F1'])]\n",
    "print(', '.join(scores))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3ec07732-2cf6-41c1-a2da-b146115d772d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329\n"
     ]
    }
   ],
   "source": [
    "ground_truth = []\n",
    "preds = []\n",
    "not_predicted = []\n",
    "for example in data:\n",
    "    question_prompt = question_prompt_template.format(example['fact_context'], example['question'])\n",
    "    prompt = example_prompt + question_prompt\n",
    "\n",
    "    response = gpt4_6_chat(prompt)\n",
    "    prediction_text = response.choices[0].message.content\n",
    "    gt = {'id':example['id'], 'answers':{'text': example['text_answers']['text']}}\n",
    "    pred = {'id':example['id'], 'no_answer_probability':0,'prediction_text':prediction_text}\n",
    "    ground_truth.append(gt)\n",
    "    preds.append(pred)\n",
    "\n",
    "print(len(preds))\n",
    "scores=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e386b9b3-0d50-46ea-96db-08a760b416e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329\n"
     ]
    }
   ],
   "source": [
    "ground_truth = []\n",
    "preds = []\n",
    "not_predicted = []\n",
    "for example in data:\n",
    "    question_prompt = question_prompt_template.format(process_context(example['context'],1024), example['question'])\n",
    "    prompt = example_prompt + question_prompt\n",
    "\n",
    "    response = gpt4_6_chat(prompt)\n",
    "    prediction_text = response.choices[0].message.content\n",
    "    gt = {'id':example['id'], 'answers':{'text': example['text_answers']['text']}}\n",
    "    pred = {'id':example['id'], 'no_answer_probability':0,'prediction_text':prediction_text}\n",
    "    ground_truth.append(gt)\n",
    "    preds.append(pred)\n",
    "\n",
    "print(len(preds))\n",
    "scores=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea21dbb2-cf8d-476e-ab18-6e5a8a15d17d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cd0099e4-4682-4979-9574-721b66d8cd60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.36, 71.84, 77.51, 81.90\n"
     ]
    }
   ],
   "source": [
    "scores=[]\n",
    "result = metric._compute( references=ground_truth, predictions=preds)\n",
    "scores += ['{:.2f}'.format(result['Set_Acc']),\"{:.2f}\".format(result['Answer_F1']),\"{:.2f}\".format(result['EM']) ,\"{:.2f}\".format(result['Token_F1'])]\n",
    "print(', '.join(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1ae6d686-470f-476d-ac0b-046caa53baf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(preds, open('llm_predictions/gpt4_preds_reason.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ed0ef828-2987-487b-aed7-118f797f45eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.36, 71.84, 77.51, 81.90\n"
     ]
    }
   ],
   "source": [
    "predictions_raw = json.load(open('gpt4_preds_reason.json'))\n",
    "data = [json.loads(line) for line in open('test_gold_gcs.json')]\n",
    "ground_truth = []\n",
    "not_predicted = []\n",
    "id2example = {}\n",
    "for example in data:\n",
    "    gt = {'id':example['id'], 'answers':{'text': example['text_answers']['text']}}\n",
    "    ground_truth.append(gt)\n",
    "    id2example[example['id']] =example\n",
    "scores=[]\n",
    "result = metric._compute( references=ground_truth, predictions=predictions_raw)\n",
    "scores += ['{:.2f}'.format(result['Set_Acc']),\"{:.2f}\".format(result['Answer_F1']),\"{:.2f}\".format(result['EM']) ,\"{:.2f}\".format(result['Token_F1'])]\n",
    "print(', '.join(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2d72f5a3-dc2c-4c41-b6b7-18c6ab87452b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7321a6d3-6de3-4550-a0eb-02c19229a258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'L3', 'L2', 'L3H', 'L2M', 'L2H', 'L3M'}\n",
      "['L2_1Target', 'L2_MTarget']\n",
      "60.62, 71.20, 73.75, 78.99, 50.00, 74.22, 91.43, 92.67\n",
      "60.62, 71.20, 73.75, 78.99, 50.00, 74.22, 91.43, 92.67, 58.36, 71.84, 77.51, 81.90\n",
      "['L2_1hop', 'L2_Mhop']\n",
      "67.13, 80.21, 51.61, 65.41\n",
      "67.13, 80.21, 51.61, 65.41, 58.36, 71.84\n"
     ]
    }
   ],
   "source": [
    "unified_data = {'L2_1Target':{'predictions':[], 'ground_truth': []},\n",
    "                'L2_MTarget':{'predictions':[], 'ground_truth': []},\n",
    "                #'L3_1Target':{'predictions':[], 'ground_truth': []},\n",
    "                #'L3_MTarget':{'predictions':[], 'ground_truth': []},\n",
    "               }\n",
    "unified_data_hop = {'L2_1hop':{'predictions':[], 'ground_truth': []},\n",
    "                'L2_Mhop':{'predictions':[], 'ground_truth': []},\n",
    "                #'L3_1hop':{'predictions':[], 'ground_truth': []},\n",
    "                #'L3_Mhop':{'predictions':[], 'ground_truth': []},\n",
    "               }\n",
    "\n",
    "lvl_sets = set()\n",
    "id2example = {}\n",
    "for example in data:\n",
    "    id2example[example['id']] = example\n",
    "for i in range(len(predictions_raw)):\n",
    "    pred = predictions_raw[i]\n",
    "    example = id2example[pred['id']]\n",
    "    elements = example['id'].split('_')\n",
    "    if len(elements)==4:\n",
    "        lvl, subj, rel, num = elements\n",
    "    elif len(elements)==5:\n",
    "        lvl, subj, rel1, rel2, num = elements\n",
    "    lvl_sets.add(lvl)\n",
    "    gt = {'id':example['id'], 'answers':{'text': example['text_answers']['text']}}\n",
    "    ground_truth.append(gt)\n",
    "    if lvl.startswith('L2') and len(example['text_answers']['text'])==1:\n",
    "        unified_data['L2_1Target']['predictions'].append(pred)\n",
    "        unified_data['L2_1Target']['ground_truth'].append(gt)\n",
    "    if lvl.startswith('L2') and len(example['text_answers']['text'])>1:\n",
    "        unified_data['L2_MTarget']['predictions'].append(pred)\n",
    "        unified_data['L2_MTarget']['ground_truth'].append(gt)\n",
    "    if lvl.startswith('L3') and len(example['text_answers']['text'])==1:\n",
    "        unified_data['L2_1Target']['predictions'].append(pred)\n",
    "        unified_data['L2_1Target']['ground_truth'].append(gt)\n",
    "    if lvl.startswith('L3') and len(example['text_answers']['text'])>1:\n",
    "        unified_data['L2_MTarget']['predictions'].append(pred)\n",
    "        unified_data['L2_MTarget']['ground_truth'].append(gt)\n",
    "    if lvl.startswith('L2'):\n",
    "        if lvl == 'L2':\n",
    "            unified_data_hop['L2_1hop']['predictions'].append(pred)\n",
    "            unified_data_hop['L2_1hop']['ground_truth'].append(gt)\n",
    "        else:\n",
    "            unified_data_hop['L2_Mhop']['predictions'].append(pred)\n",
    "            unified_data_hop['L2_Mhop']['ground_truth'].append(gt)\n",
    "    if lvl.startswith('L3'):\n",
    "        if lvl == 'L3':\n",
    "            unified_data_hop['L2_1hop']['predictions'].append(pred)\n",
    "            unified_data_hop['L2_1hop']['ground_truth'].append(gt)\n",
    "        else:\n",
    "            unified_data_hop['L2_Mhop']['predictions'].append(pred)\n",
    "            unified_data_hop['L2_Mhop']['ground_truth'].append(gt)\n",
    "\n",
    "\n",
    "print(lvl_sets)\n",
    "sums = 0\n",
    "keys = []\n",
    "scores = []\n",
    "for key in unified_data.keys():\n",
    "    #print(key)\n",
    "    preds= unified_data[key]['predictions']\n",
    "    refs= unified_data[key]['ground_truth']\n",
    "    result = metric._compute( references=refs, predictions=preds)\n",
    "    #scores += [result['Set_Acc'],result['Answer_F1']]\n",
    "    scores += ['{:.2f}'.format(result['Set_Acc']),\"{:.2f}\".format(result['Answer_F1']),\"{:.2f}\".format(result['EM']) ,\"{:.2f}\".format(result['Token_F1'])]\n",
    "    keys += [key]\n",
    "    #bin2prob[(sy,ey)] = 1 - len(refs)/1643 \n",
    "    sums+=len(refs)\n",
    "print(keys)\n",
    "print(', '.join(scores))\n",
    "keys = []\n",
    "#scores = []\n",
    "all_preds = []\n",
    "all_refs = []\n",
    "for key in unified_data.keys():\n",
    "    all_preds += unified_data[key]['predictions']\n",
    "    all_refs += unified_data[key]['ground_truth']\n",
    "result = metric._compute( references=all_refs, predictions=all_preds)\n",
    "#scores += ['{:.2f}'.format(result['Set_Acc']),\"{:.2f}\".format(result['Answer_F1']),\"{:.2f}\".format(result['EM']) ,\"{:.2f}\".format(result['Token_F1'])]\n",
    "scores += ['{:.2f}'.format(result['Set_Acc']),\"{:.2f}\".format(result['Answer_F1']),\"{:.2f}\".format(result['EM']) ,\"{:.2f}\".format(result['Token_F1'])]\n",
    "print(', '.join(scores))\n",
    "\n",
    "sums = 0\n",
    "keys = []\n",
    "scores = []\n",
    "for key in unified_data_hop.keys():\n",
    "    #print(key)\n",
    "    preds= unified_data_hop[key]['predictions']\n",
    "    refs= unified_data_hop[key]['ground_truth']\n",
    "    result = metric._compute( references=refs, predictions=preds)\n",
    "    #print('{:.1f},{:.1f}'.format(result['Set_Acc'],result['Answer_F1']))\n",
    "    #scores += [result['Set_Acc'],result['Answer_F1']]\n",
    "    scores += ['{:.2f}'.format(result['Set_Acc']),\"{:.2f}\".format(result['Answer_F1'])]\n",
    "    #scores += ['{:.2f}'.format(result['Set_Acc']),\"{:.2f}\".format(result['Answer_F1']),\"{:.2f}\".format(result['EM']) ,\"{:.2f}\".format(result['Token_F1'])]\n",
    "    keys += [key]\n",
    "    #bin2prob[(sy,ey)] = 1 - len(refs)/1643 \n",
    "    sums+=len(refs)\n",
    "print(keys)\n",
    "print(', '.join(scores))\n",
    "\n",
    "keys = []\n",
    "#scores = []\n",
    "all_preds = []\n",
    "all_refs = []\n",
    "for key in unified_data_hop.keys():\n",
    "    all_preds += unified_data_hop[key]['predictions']\n",
    "    all_refs += unified_data_hop[key]['ground_truth']\n",
    "result = metric._compute( references=all_refs, predictions=all_preds)\n",
    "#scores += ['{:.2f}'.format(result['Set_Acc']),\"{:.2f}\".format(result['Answer_F1']),\"{:.2f}\".format(result['EM']) ,\"{:.2f}\".format(result['Token_F1'])]\n",
    "scores += ['{:.2f}'.format(result['Set_Acc']),\"{:.2f}\".format(result['Answer_F1'])]\n",
    "print(', '.join(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b4ee8212-adc0-40f1-8f04-74c360f61fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'L2_Q451225_P108_4',\n",
       " 'no_answer_probability': 0,\n",
       " 'prediction_text': 'Delft University of Technology and Leiden University'}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b1222af5-22d4-49e8-847b-2cfe78009b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'L2_Q451225_P108_4',\n",
       " 'no_answer_probability': 0,\n",
       " 'prediction_text': 'Delft University of Technology and Leiden University'}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c39bd340-7686-458f-941e-1a3a701afe24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Roy Jenkins held the position of Chancellor of the Exchequer from November 1967 to June 1970. \n",
      " Roy Jenkins held the position of Representative of the Parliamentary Assembly of the Council of Europe from April 1956 to January 1957. \n",
      " Roy Jenkins held the position of Member of the 46th Parliament of the United Kingdom from February 1974 to September 1974. \n",
      " Roy Jenkins held the position of Chancellor of the University of Oxford from March 1987 to January 2003. \n",
      " Roy Jenkins held the position of Member of the 41st Parliament of the United Kingdom from May 1955 to September 1959. \n",
      " Roy Jenkins held the position of Member of the 44th Parliament of the United Kingdom from March 1966 to May 1970. \n",
      " Roy Jenkins held the position of Member of the 47th Parliament of the United Kingdom from October 1974 to January 1977. \n",
      " Roy Jenkins held the position of Member of the House of Lords from November 1987 to January 2003. \n",
      " Roy Jenkins held the position of Member of the 43rd Parliament of the United Kingdom from October 1964 to March 1966. \n",
      " Roy Jenkins was a member of the Liberal Democrats from March 1988 to January 2003. \n",
      " Roy Jenkins held the position of Member of the 49th Parliament of the United Kingdom from June 1983 to May 1987. \n",
      " Roy Jenkins held the position of Shadow Chancellor of the Exchequer from June 1970 to April 1972. \n",
      " Roy Jenkins held the position of Member of the 40th Parliament of the United Kingdom from October 1951 to May 1955. \n",
      " Roy Jenkins held the position of Shadow Home Secretary from November 1973 to March 1974. \n",
      " Roy Jenkins held the position of Substitute member of the Parliamentary Assembly of the Council of Europe from July 1955 to October 1955. \n",
      " Roy Jenkins held the position of Member of the 48th Parliament of the United Kingdom from March 1982 to May 1983. \n",
      " Roy Jenkins held the position of President of the European Commission from January 1977 to January 1981. \n",
      " Roy Jenkins held the position of Member of the 39th Parliament of the United Kingdom from February 1950 to October 1951. \n",
      " Roy Jenkins held the position of Member of the 38th Parliament of the United Kingdom from April 1948 to February 1950. \n",
      " Roy Jenkins held the position of Member of the 45th Parliament of the United Kingdom from June 1970 to February 1974. \n",
      " Roy Jenkins held the position of Member of the 42nd Parliament of the United Kingdom from October 1959 to September 1964.\n",
      "Which positions did Roy Jenkins hold when he/she was the member of Liberal Democrats?\n",
      "March 03 1988\n",
      "Chancellor of the University of Oxford and Member of the House of Lords.\n",
      "['Chancellor of the University of Oxford', 'Member of the House of Lords']\n",
      " \n",
      "2\n",
      "John von Neumann studied at University of G√∂ttingen from January 1926 to January 1927. \n",
      " John von Neumann studied at Fasori Gimn√°zium from January 1911 to January 1921. \n",
      " John von Neumann worked for Naval Ordnance Laboratory from January 1941 to January 1955. \n",
      " John von Neumann was married to Klara Dan von Neumann from January 1938 to February 1957. \n",
      " John von Neumann worked for Institute for Advanced Study from January 1933 to January 1957. \n",
      " John von Neumann worked for Princeton University from January 1930 to January 1933. \n",
      " John von Neumann worked for United States Atomic Energy Commission from January 1955 to February 1957. \n",
      " John von Neumann worked for Ballistic Research Laboratory from January 1940 to January 1941. \n",
      " John von Neumann studied at ETH Z√ºrich from January 1923 to January 1925. \n",
      " John von Neumann worked for Los Alamos National Laboratory from January 1943 to January 1955. \n",
      " John von Neumann worked for Armed Forces Special Weapons Project from January 1950 to January 1955. \n",
      " John von Neumann worked for University of Hamburg from January 1929 to January 1930.\n",
      "Which employers did John von Neumann work for when he/she was married to Klara Dan von Neumann?\n",
      "January 01 1938\n",
      "Institute for Advanced Study and Naval Ordnance Laboratory and United States Atomic Energy Commission and Los Alamos National Laboratory and Armed Forces Special Weapons Project.\n",
      "['Institute for Advanced Study', 'Ballistic Research Laboratory', 'Naval Ordnance Laboratory', 'Los Alamos National Laboratory', 'Armed Forces Special Weapons Project', 'United States Atomic Energy Commission']\n",
      " \n",
      "3\n",
      "Elon Musk worked for Neuralink from July 2016 to May 2023. \n",
      " Elon Musk was married to Talulah Riley from January 2013 to January 2016. \n",
      " Elon Musk held the position of director general from January 2008 to May 2023. \n",
      " Elon Musk held the position of chief executive officer from January 2002 to May 2023. \n",
      " Elon Musk studied at Smith School of Business from January 1990 to January 1992. \n",
      " Elon Musk worked for Tesla, Inc. from April 2004 to May 2023. \n",
      " Elon Musk studied at The Wharton School from January 1992 to January 1995. \n",
      " Elon Musk lived in Boca Chica (Texas) from June 2021 to May 2023. \n",
      " Elon Musk worked for The Boring Company from December 2016 to May 2023. \n",
      " Elon Musk worked for OpenAI from December 2015 to January 2019. \n",
      " Elon Musk was married to Justine Musk from January 2000 to January 2008. \n",
      " Elon Musk worked for SpaceX from June 2002 to May 2023.\n",
      "Which employers did Elon Musk work for when he/she held the position of director general?\n",
      "January 01 2008\n",
      "Neuralink and Tesla, Inc. and The Boring Company and SpaceX\n",
      "['SpaceX', 'Tesla, Inc.', 'OpenAI', 'Neuralink', 'The Boring Company']\n",
      " \n",
      "4\n",
      "Manuel Garc√≠a Velarde worked for Superior Technical School of Architecture of Madrid from January 1964 to January 1965. \n",
      " Manuel Garc√≠a Velarde worked for University of Texas at Austin from January 1969 to January 1971. \n",
      " Manuel Garc√≠a Velarde studied at Complutense University of Madrid from January 1959 to November 1968. \n",
      " Manuel Garc√≠a Velarde worked for Complutense University of Madrid from December 1992 to January 2011. \n",
      " Manuel Garc√≠a Velarde worked for National University of Distance Education from January 1979 to January 1993. \n",
      " Manuel Garc√≠a Velarde worked for Universit√© libre de Bruxelles from January 1965 to January 1969. \n",
      " Manuel Garc√≠a Velarde worked for Autonomous University of Madrid from January 1971 to January 1980.\n",
      "Which employer did Manuel Garc√≠a Velarde work for 8 years and 5 months after he/she worked for University of Texas at Austin?\n",
      "June 10 1979\n",
      "Autonomous University of Madrid\n",
      "['Autonomous University of Madrid', 'National University of Distance Education']\n",
      " \n",
      "5\n",
      "Denis Healey held the position of Substitute member of the Parliamentary Assembly of the Council of Europe from May 1952 to May 1953. \n",
      " Denis Healey held the position of Member of the 47th Parliament of the United Kingdom from October 1974 to April 1979. \n",
      " Denis Healey held the position of Shadow Foreign Secretary from December 1980 to June 1987. \n",
      " Denis Healey held the position of Member of the House of Lords from June 1992 to October 2015. \n",
      " Denis Healey held the position of Representative of the Parliamentary Assembly of the Council of Europe from September 1963 to September 1964. \n",
      " Denis Healey held the position of Member of the 48th Parliament of the United Kingdom from May 1979 to May 1983. \n",
      " Denis Healey held the position of Member of the 41st Parliament of the United Kingdom from May 1955 to September 1959. \n",
      " Denis Healey held the position of Member of the 46th Parliament of the United Kingdom from February 1974 to September 1974. \n",
      " Denis Healey held the position of Member of the 45th Parliament of the United Kingdom from June 1970 to February 1974. \n",
      " Denis Healey held the position of Member of the 40th Parliament of the United Kingdom from February 1952 to May 1955. \n",
      " Denis Healey held the position of Member of the 43rd Parliament of the United Kingdom from October 1964 to March 1966. \n",
      " Denis Healey held the position of Shadow Chancellor of the Exchequer from May 1979 to December 1980. \n",
      " Denis Healey held the position of Member of the 44th Parliament of the United Kingdom from March 1966 to May 1970. \n",
      " Denis Healey held the position of Member of the 42nd Parliament of the United Kingdom from October 1959 to September 1964. \n",
      " Denis Healey held the position of Chancellor of the Exchequer from March 1974 to May 1979. \n",
      " Denis Healey was married to Edna Healey from December 1945 to July 2010. \n",
      " Denis Healey held the position of Member of the 50th Parliament of the United Kingdom from June 1987 to March 1992. \n",
      " Denis Healey held the position of Member of the 49th Parliament of the United Kingdom from June 1983 to May 1987. \n",
      " Denis Healey held the position of Shadow Secretary of State for Defence from April 1964 to October 1964.\n",
      "Which position did Denis Healey hold 3 years and 6 months before he/she held the position of Shadow Foreign Secretary?\n",
      "June 18 1977\n",
      "Chancellor of the Exchequer and Member of the 48th Parliament of the United Kingdom.\n",
      "['Chancellor of the Exchequer', 'Member of the 47th Parliament of the United Kingdom']\n",
      " \n",
      "6\n",
      "Michael Batty worked for University at Buffalo from January 1990 to January 1995. \n",
      " Michael Batty received Fellow of the British Academy from January 2001 to May 2023. \n",
      " Michael Batty received Fellow of the Academy of Social Sciences from January 2001 to May 2023. \n",
      " Michael Batty worked for University of Manchester from January 1966 to January 1969. \n",
      " Michael Batty worked for Cardiff University from January 1979 to January 1990. \n",
      " Michael Batty studied at University of Manchester from January 1962 to January 1966. \n",
      " Michael Batty received Fellow of the Royal Society from January 2009 to May 2023. \n",
      " Michael Batty worked for University of Reading from January 1969 to January 1979.\n",
      "Which award did Michael Batty receive 27 years and 1 months after he/she worked for Cardiff University?\n",
      "February 05 2017\n",
      "Fellow of the Royal Society\n",
      "['Fellow of the British Academy', 'Fellow of the Academy of Social Sciences', 'Fellow of the Royal Society']\n",
      " \n",
      "7\n",
      "Elon Musk was married to Justine Musk from January 2000 to January 2008. \n",
      " Elon Musk worked for Neuralink from July 2016 to May 2023. \n",
      " Elon Musk worked for The Boring Company from December 2016 to May 2023. \n",
      " Elon Musk was married to Talulah Riley from January 2013 to January 2016. \n",
      " Elon Musk worked for OpenAI from December 2015 to January 2019. \n",
      " Elon Musk held the position of chief executive officer from January 2002 to May 2023. \n",
      " Elon Musk lived in Boca Chica (Texas) from June 2021 to May 2023. \n",
      " Elon Musk worked for SpaceX from June 2002 to May 2023. \n",
      " Elon Musk held the position of director general from January 2008 to May 2023. \n",
      " Elon Musk studied at The Wharton School from January 1992 to January 1995. \n",
      " Elon Musk studied at Smith School of Business from January 1990 to January 1992. \n",
      " Elon Musk worked for Tesla, Inc. from April 2004 to May 2023.\n",
      "Which employer did Elon Musk work for 23 years and 2 months after he/she studied at Smith School of Business?\n",
      "March 10 2015\n",
      "SpaceX and Tesla, Inc. and The Boring Company and Neuralink\n",
      "['SpaceX', 'Tesla, Inc.']\n",
      " \n",
      "8\n",
      "Elon Musk lived in Boca Chica (Texas) from June 2021 to May 2023. \n",
      " Elon Musk worked for The Boring Company from December 2016 to May 2023. \n",
      " Elon Musk studied at Smith School of Business from January 1990 to January 1992. \n",
      " Elon Musk held the position of chief executive officer from January 2002 to May 2023. \n",
      " Elon Musk worked for SpaceX from June 2002 to May 2023. \n",
      " Elon Musk was married to Justine Musk from January 2000 to January 2008. \n",
      " Elon Musk worked for Tesla, Inc. from April 2004 to May 2023. \n",
      " Elon Musk worked for OpenAI from December 2015 to January 2019. \n",
      " Elon Musk was married to Talulah Riley from January 2013 to January 2016. \n",
      " Elon Musk studied at The Wharton School from January 1992 to January 1995. \n",
      " Elon Musk held the position of director general from January 2008 to May 2023. \n",
      " Elon Musk worked for Neuralink from July 2016 to May 2023.\n",
      "Which employer did Elon Musk work for 3 years and 6 months before he/she was living in Boca Chica (Texas)?\n",
      "December 15 2017\n",
      "The Boring Company and Neuralink\n",
      "['SpaceX', 'Tesla, Inc.', 'OpenAI', 'Neuralink', 'The Boring Company']\n",
      " \n"
     ]
    }
   ],
   "source": [
    "key = 'L2_MTarget'\n",
    "exam_preds = unified_data[key]['predictions']\n",
    "exam_refs = unified_data[key]['ground_truth']\n",
    "count = 0\n",
    "for pred_ex, ref_ex in zip(exam_preds, exam_refs):\n",
    "    p_id = pred_ex['id']\n",
    "    example = id2example[p_id]\n",
    "    result = metric._compute( references=[ref_ex], predictions=[pred_ex])\n",
    "    if (result['Set_Acc'] == 0) and (result['Answer_F1'] > 0) and ('L3' in p_id):\n",
    "        print(count+1)\n",
    "        print(example['fact_context'])\n",
    "        print(example['question'])\n",
    "        print(example['date'])\n",
    "        print(pred_ex['prediction_text'])\n",
    "        print(ref_ex['answers']['text'])\n",
    "        print(' ')\n",
    "        count += 1\n",
    "        if count >=10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "71a91a45-3012-4273-8917-b99912b9543e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.5,87.5,100.0,100.0\n",
      "50.0,69.2,80.0,84.0\n",
      "60.0,77.0,85.0,85.8\n",
      "63.0,72.2,81.5,87.2\n",
      "50.0,66.9,71.9,75.2\n",
      "58.5,70.5,76.9,84.6\n",
      "59.5,71.1,73.0,77.0\n",
      "63.6,77.0,90.9,97.0\n",
      "2023\n",
      "1659\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "date_formats = {'abv_date_us':'%b %d %Y',\n",
    "                'abv_date_sg':'%d %b %Y',\n",
    "               'year':'%Y',\n",
    "               'full_date_us':'%B %d %Y',\n",
    "               'full_date_sg':'%d %B %Y',\n",
    "               'abv_month':'%b %Y', }\n",
    "\n",
    "\n",
    "\n",
    "chunk = 20\n",
    "start = 1900\n",
    "dlc_dir = ''\n",
    "yearly_bins = {}\n",
    "yearly_bins[(1000, 1900)] = {'predictions':[], 'references':[], 'examples':[],}\n",
    "\n",
    "for i in range(7):\n",
    "    sy = start + chunk * i\n",
    "    ey = sy + chunk\n",
    "    yearly_bins[(sy, ey)] = {'predictions':[], 'references':[],'examples':[] }\n",
    "\n",
    "\n",
    "intra_year = {'predictions':[], 'references':[]}\n",
    "inter_year = {'predictions':[], 'references':[]}\n",
    "\n",
    "years = []\n",
    "for pred, ref in zip(predictions_raw, ground_truth):\n",
    "    #_, s_id, rel, idx = example['id'].split('_')\n",
    "    idx = pred['id']\n",
    "    example = id2example[idx]\n",
    "    try:\n",
    "        q_date = datetime.strptime(example['date'], date_formats['full_date_us'])\n",
    "    except:\n",
    "        print(example['date'])\n",
    "    str_year = str(q_date.year)\n",
    "    num_year = q_date.year\n",
    "    years.append(num_year)\n",
    "    if  example['fact_context'].count(str_year) >=2 :\n",
    "        intra_year['predictions'].append(pred)\n",
    "        intra_year['references'].append(ref)\n",
    "\n",
    "    else:\n",
    "        inter_year['predictions'].append(pred)\n",
    "        inter_year['references'].append(ref) \n",
    "    flag = 0\n",
    "    for sy, ey in yearly_bins.keys():\n",
    "        if q_date.year in range(sy, ey):\n",
    "            yearly_bins[(sy,ey)]['predictions'].append(pred)\n",
    "            yearly_bins[(sy,ey)]['references'].append(ref)\n",
    "            yearly_bins[(sy,ey)]['examples'].append(id2example[ref['id']])\n",
    "            \n",
    "            flag = 1\n",
    "    if flag==0:\n",
    "        print(q_date.year)\n",
    "bin2prob = {}\n",
    "sums = 0\n",
    "for sy, ey in yearly_bins.keys():\n",
    "    preds= yearly_bins[(sy,ey)]['predictions']\n",
    "    refs= yearly_bins[(sy,ey)]['references']\n",
    "    examples= yearly_bins[(sy,ey)]['examples']\n",
    "    facts_lens = [len(x['fact_context'].split('\\n')) for x in examples]\n",
    "    ans_lens = [len(x['text_answers']['text']) for x in examples]\n",
    "    #print(np.mean(facts_lens))\n",
    "    #print(np.mean(ans_lens))\n",
    "    result = metric._compute( references=refs, predictions=preds)\n",
    "    #print(len(refs))\n",
    "    #print('From {} to {}:'.format(sy,ey))\n",
    "    print('{:.1f},{:.1f},{:.1f},{:.1f}'.format(result['Set_Acc'],result['Answer_F1'],result['EM'],  result['Token_F1'] ))\n",
    "    #bin2prob[(sy,ey)] = 1 - len(refs)/1643 \n",
    "    sums+=len(refs)\n",
    "\n",
    "\n",
    "print(max(years))\n",
    "print(min(years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "74a09a74-9a30-4d9c-9c82-8383a6c456b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.5,71.1,78.0,82.3\n",
      "64.9,74.2,75.7,80.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "date_formats = {'abv_date_us':'%b %d %Y',\n",
    "                'abv_date_sg':'%d %b %Y',\n",
    "               'year':'%Y',\n",
    "               'full_date_us':'%B %d %Y',\n",
    "               'full_date_sg':'%d %B %Y',\n",
    "               'abv_month':'%b %Y', }\n",
    "\n",
    "\n",
    "\n",
    "chunk = 20\n",
    "start = 1900\n",
    "dlc_dir = ''\n",
    "yearly_bins = {}\n",
    "yearly_bins[(1000, 2010)] = {'predictions':[], 'references':[], 'examples':[],}\n",
    "yearly_bins[(2010, 2040)] = {'predictions':[], 'references':[], 'examples':[],}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for pred, ref in zip(predictions_raw, ground_truth):\n",
    "    #_, s_id, rel, idx = example['id'].split('_')\n",
    "    idx = pred['id']\n",
    "    example = id2example[idx]\n",
    "    try:\n",
    "        q_date = datetime.strptime(example['date'], date_formats['full_date_us'])\n",
    "    except:\n",
    "        print(example['date'])\n",
    "    str_year = str(q_date.year)\n",
    "\n",
    "    flag = 0\n",
    "    for sy, ey in yearly_bins.keys():\n",
    "        if q_date.year in range(sy, ey):\n",
    "            yearly_bins[(sy,ey)]['predictions'].append(pred)\n",
    "            yearly_bins[(sy,ey)]['references'].append(ref)\n",
    "            yearly_bins[(sy,ey)]['examples'].append(id2example[ref['id']])\n",
    "            \n",
    "            flag = 1\n",
    "    if flag==0:\n",
    "        print(q_date.year)\n",
    "bin2prob = {}\n",
    "sums = 0\n",
    "for sy, ey in yearly_bins.keys():\n",
    "    preds= yearly_bins[(sy,ey)]['predictions']\n",
    "    refs= yearly_bins[(sy,ey)]['references']\n",
    "    examples= yearly_bins[(sy,ey)]['examples']\n",
    "    facts_lens = [len(x['fact_context'].split('\\n')) for x in examples]\n",
    "    ans_lens = [len(x['text_answers']['text']) for x in examples]\n",
    "    #print(np.mean(facts_lens))\n",
    "    #print(np.mean(ans_lens))\n",
    "    result = metric._compute( references=refs, predictions=preds)\n",
    "    #print(len(refs))\n",
    "    #print('From {} to {}:'.format(sy,ey))\n",
    "    print('{:.1f},{:.1f},{:.1f},{:.1f}'.format(result['Set_Acc'],result['Answer_F1'],result['EM'],  result['Token_F1'] ))\n",
    "    #bin2prob[(sy,ey)] = 1 - len(refs)/1643 \n",
    "    sums+=len(refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "12bcf86f-6a4c-4287-b00a-02cc0e150bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(yearly_bins[(2020, 2040)]['references']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1940e3b-45b1-4702-97f9-19312d3d1e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
